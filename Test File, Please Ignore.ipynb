{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pytorch\n",
    "import torch\n",
    "\n",
    "# define a tensor\n",
    "torch.FloatTensor([2])\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.device(0)\n",
    " torch.cuda.device_count()\n",
    "    torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def conv3x3(in_, out):\n",
    "    return nn.Conv2d(in_, out, 3, padding=1)\n",
    "\n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super().__init__()\n",
    "        self.conv = conv3x3(in_, out)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            ConvRelu(in_channels, middle_channels),\n",
    "            nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class DecoderBlockV2(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
    "        super(DecoderBlockV2, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        if is_deconv:\n",
    "            \"\"\"\n",
    "                Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
    "                link https://distill.pub/2016/deconv-checkerboard/\n",
    "            \"\"\"\n",
    "\n",
    "            self.block = nn.Sequential(\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n",
    "                                   padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                ConvRelu(middle_channels, out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet16(nn.Module):\n",
    "    def __init__(self, num_classes=1, num_filters=32, pretrained=False, is_deconv=False):\n",
    "        \"\"\"\n",
    "        :param num_classes:\n",
    "        :param num_filters:\n",
    "        :param pretrained:\n",
    "            False - no pre-trained network used\n",
    "            True - encoder pre-trained with VGG16\n",
    "        :is_deconv:\n",
    "            False: bilinear interpolation is used in decoder\n",
    "            True: deconvolution is used in decoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.encoder = torchvision.models.vgg16(pretrained=pretrained).features\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv1 = nn.Sequential(self.encoder[0],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.conv2 = nn.Sequential(self.encoder[5],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.conv3 = nn.Sequential(self.encoder[10],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.conv4 = nn.Sequential(self.encoder[17],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.conv5 = nn.Sequential(self.encoder[24],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.center = DecoderBlockV2(512, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "\n",
    "        self.dec5 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "        self.dec4 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "        self.dec3 = DecoderBlockV2(256 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv)\n",
    "        self.dec2 = DecoderBlockV2(128 + num_filters * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
    "        self.dec1 = ConvRelu(64 + num_filters, num_filters)\n",
    "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(self.pool(conv1))\n",
    "        conv3 = self.conv3(self.pool(conv2))\n",
    "        conv4 = self.conv4(self.pool(conv3))\n",
    "        #conv5 = self.conv5(self.pool(conv4))\n",
    "\n",
    "        center = self.center(self.pool(conv4))\n",
    "\n",
    "        dec4 = self.dec5(torch.cat([center, conv4], 1))\n",
    "\n",
    "        #dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
    "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
    "\n",
    "        if self.num_classes > 1:\n",
    "            x_out = F.log_softmax(self.final(dec1), dim=1)\n",
    "        else:\n",
    "            x_out = self.final(dec1)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 416, 416])\n"
     ]
    }
   ],
   "source": [
    "# model = UNet16(num_classes=1, num_filters=32, pretrained=True, is_deconv=True)\n",
    "model = nn.Conv2d(3,1,3, padding=1)\n",
    "#test = nn.ConvTranspose2d(3, 6, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "input = torch.rand(1, 3, 416, 416)\n",
    "print(input.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 416, 416])\n"
     ]
    }
   ],
   "source": [
    "output = model(input)\n",
    "print(output.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "#import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "import os\n",
    "\n",
    "#plotly.__version__\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "plotly.io.orca.config.executable = '/home/royce/orca/orca-1.2.1-x86_64.AppImage'\n",
    "plotly.io.orca.config.save() \n",
    "\n",
    "class potly(object):\n",
    "    def __init__(self, pot=0):\n",
    "        self.pot = 0\n",
    "    \n",
    "\n",
    "    def save_plot(self, train_y, val_y, output_dir, filename):\n",
    "#         if(len(train_y) != len(val_y)):\n",
    "#             print(\"Train not same length as validation\")\n",
    "        \n",
    "        # get x axis\n",
    "        train_x = [i for i in range(len(train_y))]\n",
    "        val_x = [i for i in range(len(val_y))]\n",
    "        \n",
    "        # create plots\n",
    "        fig1 = go.Scatter(x=train_x, y=train_y, name='training')\n",
    "        fig2 = go.Scatter(x=val_x, y=val_y, name='validation')\n",
    "        \n",
    "        # needed for data input\n",
    "        data = [fig1, fig2]\n",
    "        \n",
    "        # create layout: titles\n",
    "        layout = go.Layout(\n",
    "            title='Final Epochs',\n",
    "            xaxis=dict(\n",
    "                title='Epoch #',\n",
    "                titlefont=dict(\n",
    "                    family='Courier New, monospace',\n",
    "                    size=18,\n",
    "                    color='#7f7f7f'\n",
    "                )\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title='Loss',\n",
    "                titlefont=dict(\n",
    "                    family='Courier New, monospace',\n",
    "                    size=18,\n",
    "                    color='#7f7f7f'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # load data and layout\n",
    "        fig = go.Figure(data=data, layout=layout)\n",
    "        \n",
    "        # double check to make sure if directory exists\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        pio.write_image(fig, output_dir + filename + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.6054948834180832, 0.5342046623080969, 0.46604244205355644]], [[0.005458398520946503, 0.005060129016637802, 0.004333792626857758]]]\n",
      "[[[0.38173164850473407]], [[0.003895449012517929]]]\n",
      "[[[0.3695145677104592, 0.36339623710513114, 0.3448032429926097]], [[0.00371395069360733, 0.004109779700636864, 0.0034569417238235474]]]\n",
      "[[[0.3426332968175411, 0.34493934413790706, 0.32968188293278217, 0.321596234023571]], [[0.0036532875150442124, 0.00336752200871706, 0.0032557889595627785, 0.0035381605625152586]]]\n",
      "[[[0.31752758847177026, 0.32328712229430673, 0.31472743723541496]], [[0.0029422275945544243, 0.0033178173527121544, 0.0031131386756896974]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "#import potly\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "with open('./data/logs/epoch - 2019-04-23-3.log', 'r') as data_file:\n",
    "    json_data_1 = data_file.read()\n",
    "\n",
    "with open('./data/logs/epoch - 2019-04-24-5.log', 'r') as data_file:\n",
    "    json_data_2 = data_file.read()\n",
    "    \n",
    "with open('./data/logs/epoch - 2019-04-25-6.log', 'r') as data_file:\n",
    "    json_data_3 = data_file.read()\n",
    "    \n",
    "with open('./data/logs/epoch - 2019-04-25-7.log', 'r') as data_file:\n",
    "    json_data_4 = data_file.read()\n",
    "    \n",
    "with open('./data/logs/epoch - 2019-04-26-8.log', 'r') as data_file:\n",
    "    json_data_5 = data_file.read()\n",
    "\n",
    "data1 = json.loads(json_data_1)\n",
    "data2 = json.loads(json_data_2)\n",
    "data3 = json.loads(json_data_3)\n",
    "data4 = json.loads(json_data_4)\n",
    "data5 = json.loads(json_data_5)\n",
    "\n",
    "#pot = potly()\n",
    "#output_dir = './data/outputs/plots/'\n",
    "#filename = str(datetime.now().date()) + \"-1\"\n",
    "#N = 100\n",
    "#x = val[0][0]\n",
    "#y = val[1][0]\n",
    "\n",
    "#pot.save_plot(x,y,output_dir, filename)\n",
    "print(data1)\n",
    "print(data2)\n",
    "print(data3)\n",
    "print(data4)\n",
    "print(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6054948834180832, 0.5342046623080969, 0.46604244205355644, 0.38173164850473407, 0.3695145677104592, 0.36339623710513114, 0.3448032429926097, 0.3426332968175411, 0.34493934413790706, 0.32968188293278217, 0.321596234023571, 0.31752758847177026, 0.32328712229430673, 0.31472743723541496]\n",
      "[0.5458398520946502, 0.5060129016637802, 0.4333792626857758, 0.3895449012517929, 0.371395069360733, 0.41097797006368636, 0.3456941723823547, 0.36532875150442123, 0.336752200871706, 0.32557889595627787, 0.35381605625152585, 0.2942227594554424, 0.33178173527121546, 0.3113138675689697]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for data in [data1, data2, data3, data4, data5]:\n",
    "    for i in range(len(data[0][0])):\n",
    "        x.append(data[0][0][i])\n",
    "        y.append(data[1][0][i])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot = potly()\n",
    "output_dir = './data/outputs/plots/'\n",
    "filename = \"final run\"\n",
    "pot.save_plot(x,y,output_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randint\n",
    "import dataGenerator\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "dat = dataGenerator.dataGenerator(416)\n",
    "random_test_filenames = [randint(0,100000) for _ in range(5)]\n",
    "outputs_dir = \"./data/outputs/\" + str(datetime.now().date())\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "\n",
    "photo_dir = './data/train/photos/'\n",
    "tensor_dir = './data/train/tensors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_paths = [photo_dir + str(random_test_filenames[i]) + '.png' for i in range(5)]\n",
    "tensor_paths = [tensor_dir + str(random_test_filenames[i]) + '.pt' for i in range(5)]\n",
    "threshold = 1\n",
    "\n",
    "for i in range(5):\n",
    "    img = Image.open(photo_paths[i])\n",
    "    tensor = torch.load(tensor_paths[i])\n",
    "    #img = dat.showDefaultTensor(img, tensor, threshold)\n",
    "    img = dat.showMaskOnImage(img, tensor, threshold)\n",
    "    img.save(outputs_dir  + \"/MoI_Test 3 - \" + str(random_test_filenames[i]) + \".png\",\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "torchvision.models.vgg16(pretrained=True).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dataGenerator.dataGenerator(416)\n",
    "j = 0\n",
    "outputs_dir = \"data/outputs/\" + str(datetime.now().date())\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "threshold = 0.05\n",
    "batch = 3\n",
    "\n",
    "for locations in paths:\n",
    "    img = Image.open(locations)\n",
    "    img = dat.showMaskOnImage(img,outputs[j], threshold)\n",
    "    img.save(outputs_dir  + \"/batch_\" + str(batch) + \"-\" + str(j) + \".png\",\"PNG\")\n",
    "    #img.show()\n",
    "    j += 1\n",
    "\n",
    "#Cells\n",
    "outputs[0]\n",
    "    \n",
    "#Cells\n",
    "locations = \"/data/photos/999.png\"\n",
    "loc = locations.replace(\"/data/photos/\", \"\").replace(\".png\", \"\")\n",
    "\n",
    "print(locations)\n",
    "print(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
