{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import dataGenerator\n",
    "import logly\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Values\n",
    "show_live_loss = False\n",
    "newTraining = True\n",
    "save_masks = False\n",
    "print_loss = True\n",
    "output_tensors = False\n",
    "train_flag = True\n",
    "EPOCHS = 3\n",
    "iteration = \"-11\"\n",
    "\n",
    "# default values\n",
    "NUM_CLASSES = 1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batchSize = 50\n",
    "#val_batch_size = 100\n",
    "num_batch = 2000 #25000 #11112\n",
    "val_batch = 2\n",
    "imageSize = 416\n",
    "SAVE_LOCATION = \"./data/models/model_test\"\n",
    "LOAD_LOCATION = \"./data/models/model_best\"\n",
    "INTERRUPTED_LOCATION =  \"./data/models/model_interrupted\"\n",
    "train_dir = \"./data/train/\"\n",
    "val_dir = \"./data/validation/\"\n",
    "log_dir = './data/logs/'\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        \n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        \n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        \n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.Resize([imageSize,imageSize]),\n",
    "                                      transforms.ToTensor()\n",
    "                                     ])\n",
    "\n",
    "# instantiate the dataset and dataloader\n",
    "train_dataset = ImageFolderWithPaths(train_dir, transform=data_transforms) # our custom dataset\n",
    "val_dataset = ImageFolderWithPaths(val_dir, transform=data_transforms) # our custom dataset\n",
    "\n",
    "#loads only photos\n",
    "train_dataloaders = torch.utils.data.DataLoader(train_dataset, batch_size = batchSize, shuffle=True)\n",
    "val_dataloaders = torch.utils.data.DataLoader(val_dataset, batch_size = batchSize, shuffle=True)\n",
    "\n",
    "data_factory = dataGenerator.dataGenerator(IMAGE_SIZE=imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training W/O Val Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=4):\n",
    "    # time\n",
    "    since = time.time()\n",
    "    best_model = None\n",
    "    best_loss = math.inf\n",
    "    \n",
    "    outputs_dir = \"data/outputs/results/\" + str(datetime.now().date())\n",
    "    os.makedirs(outputs_dir, exist_ok=True)\n",
    "    \n",
    "    # logs\n",
    "    batch_log = logly.logly(True, num_epochs, num_batch)\n",
    "    epoch_log = logly.logly(True, 1, num_epochs)\n",
    "    batch_log_name = str(datetime.now().date()) + iteration\n",
    "    epoch_log_name = \"epoch - \"+ str(datetime.now().date()) + iteration\n",
    "    \n",
    "    # model and sigmoid function\n",
    "    model = model.to(device)\n",
    "    sigmoid_function = nn.Sigmoid()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if print_loss:\n",
    "            print('Epoch {}/{}'.format(epoch + 1, num_epochs), flush=True)\n",
    "            \n",
    "        epoch_loss = 0\n",
    "        \n",
    "        #Training    \n",
    "        model.train()\n",
    "        phase = 'train'\n",
    "        for batch in range(num_batch):\n",
    "            if print_loss:\n",
    "                print('Batch {}/{}'.format(batch + 1, num_batch), flush=True)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            \n",
    "            #BATCH TUPLE\n",
    "            inputs, labels, paths = next(iter(train_dataloaders))\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            i = 0\n",
    "            labels = torch.zeros(batchSize,NUM_CLASSES,imageSize,imageSize).to(device)\n",
    "\n",
    "            #build ground-truth batch tensor\n",
    "            for locations in paths:\n",
    "                loc = locations.replace(\".png\", \".pt\").replace(\"photos\", \"tensors\")\n",
    "                labels[i] = torch.load(loc)\n",
    "                i += 1\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                #build input-truth batch tensor\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels) #ground truth comparison\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # backward + optimize \n",
    "                    loss.backward() #modifies model\n",
    "                    optimizer.step() \n",
    "\n",
    "                # statistics\n",
    "                epoch_loss += loss.item()\n",
    "                running_loss = loss.item()\n",
    "\n",
    "            batch_log.log(phase, epoch, batch, running_loss)\n",
    "            \n",
    "            if batch % 20 == 0:\n",
    "                batch_log.write(log_dir, batch_log_name)\n",
    "            \n",
    "            if print_loss:\n",
    "                print(\"loss: {}\".format(running_loss), flush=True)\n",
    "                print('---------------', flush=True)\n",
    "        \n",
    "        epoch_loss /= val_batch\n",
    "        epoch_log.log(phase, 0, epoch, epoch_loss)\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        phase = 'val'\n",
    "        val_loss = 0\n",
    "        for batch in range(val_batch):\n",
    "            if print_loss:\n",
    "                print('Val-Batch {}/{}'.format(batch + 1, val_batch), flush=True)\n",
    "            \n",
    "            #BATCH TUPLE\n",
    "#           inputs, labels, paths = next(iter(train_dataloaders))\n",
    "            inputs, labels, paths = next(iter(val_dataloaders))\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            i = 0\n",
    "            labels = torch.zeros(batchSize,NUM_CLASSES,imageSize,imageSize).to(device)\n",
    "\n",
    "            #build ground-truth batch tensor\n",
    "            for locations in paths:\n",
    "                loc = locations.replace(\".png\", \".pt\").replace(\"photos\", \"tensors\")\n",
    "                labels[i] = torch.load(loc)\n",
    "                i += 1\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                #build input-truth batch tensor\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels) #ground truth comparison\n",
    "\n",
    "                # statistics\n",
    "                val_loss += loss.item()\n",
    "                running_loss = loss.item()\n",
    "\n",
    "            batch_log.log(phase, epoch, batch, running_loss)\n",
    "            \n",
    "            if batch % 20 == 0:\n",
    "                batch_log.write(log_dir, batch_log_name)\n",
    "                \n",
    "            if print_loss:\n",
    "                print(\"loss: {}\".format(running_loss), flush=True)\n",
    "                print('---------------', flush=True)\n",
    "            \n",
    "            if save_masks and phase == 'val':\n",
    "                outputs = sigmoid_function(outputs)\n",
    "                j = 0\n",
    "                for locations in paths:\n",
    "                    img = Image.open(locations)\n",
    "#                     num = locations.replace(\"./data/train/photos/\", \"\").replace(\".png\", \"\")\n",
    "#                     num = locations.replace(\"./data/validation/photos/\", \"\").replace(\".png\", \"\")\n",
    "                    for threshold in [0.05, .25, .5, .75]:\n",
    "                        img = data_factory.showMaskOnImage(img,outputs[j], threshold)\n",
    "                        img.save(outputs_dir  + \"/train-\" + str(num) + \"-\" + str(epoch) + \"-t\" + str(threshold) + \".png\",\"PNG\")\n",
    "                    j += 1\n",
    "                \n",
    "        val_loss /= num_batch\n",
    "        epoch_log.log(phase, 0, epoch, val_loss)\n",
    "        \n",
    "        epoch_log.write(log_dir, epoch_log_name)    \n",
    "\n",
    "#             if output_tensors:\n",
    "#                 return inputs, outputs, paths\n",
    "\n",
    "        #save best copy of  model\n",
    "        #if phase == 'val' and epoch_loss < best_loss:\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model, LOAD_LOCATION)\n",
    "            torch.save(model, SAVE_LOCATION)\n",
    "            torch.save(model.state_dict(), LOAD_LOCATION + \"-\" + str(datetime.now().date()) + iteration) \n",
    "        \n",
    "    #save current model\n",
    "    torch.save(model,SAVE_LOCATION)\n",
    "    batch_log.write(log_dir, batch_log_name)\n",
    "    epoch_log.write(log_dir, epoch_log_name)\n",
    "    \n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.1f}m {:.1f}s'.format(time_elapsed // 60, time_elapsed % 60), flush=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single convolution model with weights?\n"
     ]
    }
   ],
   "source": [
    "from unet_models import *\n",
    "\n",
    "#imports related to UNet\n",
    "if newTraining:\n",
    "    model = UNet1(num_classes=1, num_filters=32, pretrained=True, is_deconv=True)\n",
    "    print('Single convolution model with weights', flush=True)\n",
    "#     model = UNet16_5(num_classes=1, num_filters=32, pretrained=True, is_deconv=True)\n",
    "    \n",
    "#     print('initializing model with random weights', flush=True)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.center.children())[1].weight)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.dec5.children())[1].weight)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.dec4.children())[1].weight)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.dec3.children())[1].weight)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.dec2.children())[1].weight)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.dec1.children()).weight)\n",
    "#     torch.nn.init.xavier_uniform_(model.final.weight)\n",
    "                           \n",
    "else:\n",
    "    print(\"loading weights from\", LOAD_LOCATION, flush=True)\n",
    "    #model = torch.load(SAVE_LOCATION)\n",
    "    model = torch.load(LOAD_LOCATION)\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "#criterion = DICELossMultiClass()\n",
    "#criterion = IOU_BCELoss()\n",
    "\n",
    "#Observe adjustments in learning rate\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.05, weight_decay=0, amsgrad=False, eps=0.1)\n",
    "\n",
    "# Osscilate between high and low learning rates over time\n",
    "exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=EPOCHS,eta_min=0.001)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=EPOCHS)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    torch.save(model, INTERRUPTED_LOCATION)\n",
    "    print('Saved interrupt', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    inputs, outputs, paths = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=EPOCHS)\n",
    "    #batch = \n",
    "except KeyboardInterrupt:\n",
    "    torch.save(model, INTERRUPTED_LOCATION)\n",
    "    print('Saved interrupt', flush=True)\n",
    "\n",
    "# for tensor in labels:\n",
    "#     #tensor = labels[0]\n",
    "#     tensor_max_value = torch.max(tensor)\n",
    "#     print(tensor_max_value)\n",
    "#     print(type(tensor_max_value.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save state model as model\n",
    "model = UNet16_5(num_classes=1, num_filters=32, pretrained=True, is_deconv=True)\n",
    "model.load_state_dict(torch.load(LOAD_LOCATION+'_test-2019-04-23-3'))\n",
    "torch.save(model, LOAD_LOCATION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
