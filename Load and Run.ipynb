{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.Resize([imageSize,imageSize]),\n",
    "                                      transforms.ToTensor()\n",
    "                                     ])\n",
    "\n",
    "# instantiate the dataset and dataloader\n",
    "dataset = ImageFolderWithPaths(data_dir, transform=data_transforms) # our custom dataset\n",
    "\n",
    "#loads only photos\n",
    "dataloaders = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle=True)\n",
    "\n",
    "new_road_factory = DrawingWithTensors.datasetFactory(IMAGE_SIZE=imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training W/O Val Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=4):\n",
    "    since = time.time()\n",
    "    best_model = None\n",
    "    best_loss = math.inf\n",
    "    model.train()  \n",
    "    for epoch in range(1,num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1), flush=True)\n",
    "        epoch_loss = 0\n",
    "   \n",
    "        #BATCH TUPLE\n",
    "        inputs, labels, paths = next(iter(dataloaders))\n",
    "        inputs.to(device)\n",
    "                \n",
    "        #build ground-truth batch tensor\n",
    "        for locations in paths:\n",
    "            i = 0\n",
    "            #dtype=torch.int64\n",
    "            labels = torch.zeros(batchSize,NUM_CLASSES,imageSize,imageSize, dtype = torch.float32).to(device)\n",
    "            labels[i] = torch.load(locations.replace(\".png\", \".pt\").replace(\"roads\", \"tensor_values\")) \n",
    "            i += 1\n",
    "            \n",
    "        # forward\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            #build input-truth batch tensor\n",
    "            outputs = model(inputs.to(device)).to(device)\n",
    "            loss = criterion(outputs, labels) #ground truth comparison\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # backward + optimize \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # statistics\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(\"loss: {}\".format(epoch_loss), flush=True)\n",
    "        print('---------------', flush=True)\n",
    "        \n",
    "        #save best copy of  model\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model, SAVE_LOCATION.replace(\"model\", \"model_best\"))\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    \n",
    "    print('Training complete in {:.1f}m {:.1f}s'.format(time_elapsed // 60, time_elapsed % 60), flush=True)\n",
    "\n",
    "    #completed model\n",
    "    torch.save(model,SAVE_LOCATION)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
