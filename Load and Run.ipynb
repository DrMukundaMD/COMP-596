{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import dataGenerator\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Values\n",
    "show_live_loss = False\n",
    "newTraining = False\n",
    "show_outputs = True\n",
    "print_loss = False\n",
    "EPOCHS = 1\n",
    "\n",
    "# default values\n",
    "NUM_CLASSES = 1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batchSize = 3\n",
    "iteration = \"1\"\n",
    "imageSize = 416\n",
    "cwd = os.getcwd()\n",
    "SAVE_LOCATION = cwd + \"/data/models/model_test\"\n",
    "LOAD_LOCATION = cwd + \"/data/models/model_test\"\n",
    "INTERRUPTED_LOCATION = cwd + \"/data/models/model_interrupted\"\n",
    "#data_dir = cwd + \"/data/photos/\"\n",
    "data_dir = \"./data/\"\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.Resize([imageSize,imageSize]),\n",
    "                                      transforms.ToTensor()\n",
    "                                     ])\n",
    "\n",
    "# instantiate the dataset and dataloader\n",
    "dataset = ImageFolderWithPaths(data_dir, transform=data_transforms) # our custom dataset\n",
    "\n",
    "#loads only photos\n",
    "dataloaders = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle=True)\n",
    "\n",
    "new_road_factory = dataGenerator.dataGenerator(IMAGE_SIZE=imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training W/O Val Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=4):\n",
    "    since = time.time()\n",
    "    best_model = None\n",
    "    best_loss = math.inf\n",
    "    model.train()  \n",
    "    liveloss = PlotLosses()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if print_loss:\n",
    "            print('Epoch {}/{}'.format(epoch + 1, num_epochs), flush=True)\n",
    "        epoch_loss = 0\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        logs = {}\n",
    "        \n",
    "        #BATCH TUPLE\n",
    "        inputs, labels, paths = next(iter(dataloaders))\n",
    "        inputs.to(device)\n",
    "        #labels.to(device)\n",
    "        \n",
    "        # Moved outside paths forloop as labels would be reset\n",
    "        i = 0\n",
    "        labels = torch.zeros(batchSize,NUM_CLASSES,imageSize,imageSize).to(device)\n",
    "        \n",
    "        #build ground-truth batch tensor\n",
    "        for locations in paths:\n",
    "            #dtype=torch.int64\n",
    "            ### Why are we using float?\n",
    "            #labels = torch.zeros(batchSize,NUM_CLASSES,imageSize,imageSize, dtype = torch.float32).to(device)\n",
    "            loc = locations.replace(\".png\", \".pt\").replace(\"photos\", \"tensors\")\n",
    "            labels[i] = torch.load(loc)\n",
    "            #print(\"loading tensor:\", i,  loc, flush=True)\n",
    "            #print(\"tensor max:\", torch.max(labels[i]))\n",
    "            i += 1\n",
    "            \n",
    "        # forward\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            #build input-truth batch tensor\n",
    "            outputs = model(inputs.to(device)).to(device)\n",
    "            #outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels) #ground truth comparison\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # backward + optimize \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # statistics\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        \n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         running_loss += loss.detach() * inputs.size(0)\n",
    "#         running_corrects += torch.sum(preds == labels.data, dtype = torch.float32)\n",
    "#         labels = labels.to(dtype=torch.long)\n",
    "#         running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "#         e_loss = running_loss / len(dataloaders.dataset)\n",
    "#         epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
    "\n",
    "#         print(\"Running corrects: {}\".format(running_corrects), flush=True)\n",
    "        \n",
    "        logs['log loss'] = epoch_loss\n",
    "        #logs['accuracy'] = epoch_acc\n",
    "        logs['accuracy'] = 1 - epoch_loss\n",
    "        \n",
    "        if show_live_loss:\n",
    "            liveloss.update(logs)\n",
    "            liveloss.draw()\n",
    "            \n",
    "        if show_outputs:\n",
    "            j = 0\n",
    "            dat = dataGenerator.dataGenerator(416)\n",
    "            for locations in paths:\n",
    "                img = Image.open(locations)\n",
    "                img = dat.showMaskOnImage(img,outputs[j])\n",
    "                img.show()\n",
    "                \n",
    "        if print_loss:\n",
    "            print(\"loss: {}\".format(epoch_loss), flush=True)\n",
    "            print('---------------', flush=True)\n",
    "        \n",
    "        #save best copy of  model\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), SAVE_LOCATION.replace(\"test\", \"best\"))\n",
    "            torch.save(model.state_dict(), SAVE_LOCATION.replace(\"test\", \"best\") + \"-\" + str(datetime.now().date()))\n",
    "            #torch.save(model, SAVE_LOCATION)\n",
    "            #torch.save(model, SAVE_LOCATION.replace(\"model\", \"model_best\"))\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    \n",
    "    print('Training complete in {:.1f}m {:.1f}s'.format(time_elapsed // 60, time_elapsed % 60), flush=True)\n",
    "\n",
    "    #completed model\n",
    "    torch.save(model,SAVE_LOCATION)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from /home/royce/workspace/research/COMP-596/data/models/model_test\n"
     ]
    }
   ],
   "source": [
    "from unet_models import *\n",
    "\n",
    "#imports related to UNet\n",
    "if newTraining:\n",
    "    model = UNet16(num_classes=1, num_filters=32, pretrained=True, is_deconv=True)\n",
    "    \n",
    "    print('initializing model with random weights', flush=True)\n",
    "    torch.nn.init.xavier_uniform_(next(model.center.children())[1].weight)\n",
    "    \n",
    "    torch.nn.init.xavier_uniform_(next(model.dec5.children())[1].weight)\n",
    "    \n",
    "    torch.nn.init.xavier_uniform_(next(model.dec4.children())[1].weight)\n",
    "\n",
    "    torch.nn.init.xavier_uniform_(next(model.dec3.children())[1].weight)\n",
    "\n",
    "    torch.nn.init.xavier_uniform_(next(model.dec2.children())[1].weight)\n",
    "\n",
    "    torch.nn.init.xavier_uniform_(next(model.dec1.children()).weight)\n",
    "\n",
    "    torch.nn.init.xavier_uniform_(model.final.weight)\n",
    "                           \n",
    "else:\n",
    "    print(\"loading weights from\", LOAD_LOCATION, flush=True)\n",
    "    #model = torch.load(SAVE_LOCATION)\n",
    "    model = torch.load(LOAD_LOCATION)\n",
    "    \n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "#criterion = DICELossMultiClass()\n",
    "#criterion = IOU_BCELoss()\n",
    "\n",
    "#Observe adjustments in learning rate\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.05,weight_decay=0, amsgrad=False, eps=0.1)\n",
    "\n",
    "# Osscilate between high and low learning rates over time\n",
    "exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=EPOCHS,eta_min=0.001)  \n",
    "\n",
    "\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 0.0m 33.9s\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=EPOCHS)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(model, INTERRUPTED_LOCATION)\n",
    "    print('Saved interrupt', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tensor in labels:\n",
    "#     #tensor = labels[0]\n",
    "#     tensor_max_value = torch.max(tensor)\n",
    "#     print(tensor_max_value)\n",
    "#     print(type(tensor_max_value.item()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
