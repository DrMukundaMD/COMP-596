{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import dataGenerator\n",
    "import logly\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# class Company(object):\n",
    "#     def __init__(self, name, value):\n",
    "#         self.name = name\n",
    "#         self.value = value\n",
    "\n",
    "# with open('company_data.pkl', 'wb') as output:\n",
    "#     company1 = Company('banana', 40)\n",
    "#     pickle.dump(company1, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#     company2 = Company('spam', 42)\n",
    "#     pickle.dump(company2, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# del company1\n",
    "# del company2\n",
    "\n",
    "# with open('company_data.pkl', 'rb') as input:\n",
    "#     company1 = pickle.load(input)\n",
    "#     print(company1.name)  # -> banana\n",
    "#     print(company1.value)  # -> 40\n",
    "\n",
    "#     company2 = pickle.load(input)\n",
    "#     print(company2.name) # -> spam\n",
    "#     print(company2.value)  # -> 42\n",
    "\n",
    "    \n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# sample usage\n",
    "#save_object(company1, 'company1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Values\n",
    "show_live_loss = False\n",
    "newTraining = True\n",
    "save_masks = True\n",
    "print_loss = True\n",
    "output_tensors = False\n",
    "train_flag = True\n",
    "EPOCHS = 1\n",
    "iteration = \"-\"\n",
    "\n",
    "# default values\n",
    "NUM_CLASSES = 1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batchSize = 8\n",
    "num_batch = 1 #25000 #11112\n",
    "val_batch = 1\n",
    "imageSize = 416\n",
    "SAVE_LOCATION = \"./data/models/model_test\"\n",
    "LOAD_LOCATION = \"./data/models/model_best\"\n",
    "INTERRUPTED_LOCATION =  \"./data/models/model_interrupted\"\n",
    "train_dir = \"./data/train/\"\n",
    "val_dir = \"./data/validation/\"\n",
    "log_dir = './data/logs/'\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        \n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        \n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        \n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.Resize([imageSize,imageSize]),\n",
    "                                      transforms.ToTensor()\n",
    "                                     ])\n",
    "\n",
    "# instantiate the dataset and dataloader\n",
    "train_dataset = ImageFolderWithPaths(train_dir, transform=data_transforms) # our custom dataset\n",
    "val_dataset = ImageFolderWithPaths(val_dir, transform=data_transforms) # our custom dataset\n",
    "\n",
    "#loads only photos\n",
    "train_dataloaders = torch.utils.data.DataLoader(train_dataset, batch_size = batchSize, shuffle=True)\n",
    "val_dataloaders = torch.utils.data.DataLoader(val_dataset, batch_size = batchSize, shuffle=True)\n",
    "\n",
    "data_factory = dataGenerator.dataGenerator(IMAGE_SIZE=imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training W/O Val Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=4):\n",
    "    since = time.time()\n",
    "    best_model = None\n",
    "    best_loss = math.inf\n",
    "    #model.train()  \n",
    "    #liveloss = PlotLosses()\n",
    "    model = model.to(device)\n",
    "    sigmoid_function = nn.Sigmoid()\n",
    "    batch_log = logly.logly(True, num_epochs, num_batch)\n",
    "    epoch_log = logly.logly(True, 1, num_epochs)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if print_loss:\n",
    "            print('Epoch {}/{}'.format(epoch + 1, num_epochs), flush=True)\n",
    "        \n",
    "#         #Training    \n",
    "#         model.train()\n",
    "#         phase = 'train'\n",
    "#         epoch_loss = 0\n",
    "#         for batch in range(num_batch):\n",
    "#             running_loss = 0.0\n",
    "            \n",
    "#             if print_loss:\n",
    "#                 #print('Epoch {}/{}'.format(epoch + 1, num_epochs), flush=True)\n",
    "#                 print('Batch {}/{}'.format(batch + 1, num_batch), flush=True)\n",
    "            \n",
    "#             #BATCH TUPLE\n",
    "#             inputs, labels, paths = next(iter(train_dataloaders))\n",
    "#             inputs = inputs.to(device)\n",
    "#             #labels.to(device)\n",
    "\n",
    "#             # Moved outside paths forloop as labels would be reset\n",
    "#             i = 0\n",
    "#             labels = torch.zeros(batchSize,NUM_CLASSES,imageSize,imageSize).to(device)\n",
    "\n",
    "#             #build ground-truth batch tensor\n",
    "#             for locations in paths:\n",
    "#                 #dtype=torch.int64\n",
    "#                 ### Why are we using float?\n",
    "#                 #labels = torch.zeros(batchSize,NUM_CLASSES,imageSize,imageSize, dtype = torch.float32).to(device)\n",
    "#                 loc = locations.replace(\".png\", \".pt\").replace(\"photos\", \"tensors\")\n",
    "#                 labels[i] = torch.load(loc)\n",
    "#                 #print(\"loading tensor:\", i,  loc, flush=True)\n",
    "#                 #print(\"tensor max:\", torch.max(labels[i]))\n",
    "#                 i += 1\n",
    "\n",
    "#             if train_flag:\n",
    "#                 phase = 'train'\n",
    "#                 #print(\"Setting model in training mode\")\n",
    "#                 # Set model to training mode\n",
    "#                 model.train() \n",
    "#             else:\n",
    "#                 phase = 'val'\n",
    "#                 #print(\"Setting model in validation mode\")\n",
    "#                 # Set model to evaluate mode\n",
    "#                 model.eval()\n",
    "\n",
    "#             # forward\n",
    "#             # track history if only in train\n",
    "#             with torch.set_grad_enabled(phase == 'train'):\n",
    "#                 #build input-truth batch tensor\n",
    "#                 outputs = model(inputs)\n",
    "#                 #outputs = model(inputs.to(device)).to(device)\n",
    "#                 #outputs = model(inputs)\n",
    "#                 loss = criterion(outputs, labels) #ground truth comparison\n",
    "\n",
    "#                 if phase == 'train':\n",
    "#                     # zero the parameter gradients\n",
    "#                     optimizer.zero_grad()\n",
    "\n",
    "#                     # backward + optimize \n",
    "#                     loss.backward() #modifies model\n",
    "#                     optimizer.step() \n",
    "\n",
    "#                 # statistics\n",
    "#                 epoch_loss += loss.item()\n",
    "#                 running_loss = loss.item()\n",
    "\n",
    "#             #\n",
    "            \n",
    "#             batch_log.log(phase, epoch, batch, running_loss)\n",
    "            \n",
    "#             if batch % 20 == 0:\n",
    "#                 log_name = str(datetime.now().date()) + iteration\n",
    "#                 batch_log.write(log_dir, log_name)\n",
    "            \n",
    "#             if print_loss:\n",
    "#                 print(\"loss: {}\".format(running_loss), flush=True)\n",
    "#                 print('---------------', flush=True)\n",
    "        \n",
    "#         epoch_loss /= val_batch\n",
    "#         epoch_log.log(phase, 0, epoch, epoch_loss)\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        phase = 'val'\n",
    "        val_loss = 0\n",
    "        for batch in range(val_batch):\n",
    "            if print_loss:\n",
    "                print('Val-Batch {}/{}'.format(batch + 1, val_batch), flush=True)\n",
    "            \n",
    "            #BATCH TUPLE\n",
    "            inputs, labels, paths = next(iter(train_dataloaders))\n",
    "            #inputs, labels, paths = next(iter(val_dataloaders))\n",
    "            inputs = inputs.to(device)\n",
    "            #labels.to(device)\n",
    "\n",
    "            # Moved outside paths forloop as labels would be reset\n",
    "            i = 0\n",
    "            labels = torch.zeros(batchSize,NUM_CLASSES,imageSize,imageSize).to(device)\n",
    "\n",
    "            #build ground-truth batch tensor\n",
    "            for locations in paths:\n",
    "                loc = locations.replace(\".png\", \".pt\").replace(\"photos\", \"tensors\")\n",
    "                labels[i] = torch.load(loc)\n",
    "                i += 1\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                #build input-truth batch tensor\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels) #ground truth comparison\n",
    "\n",
    "                # statistics\n",
    "                val_loss += loss.item()\n",
    "                running_loss = loss.item()\n",
    "\n",
    "            batch_log.log(phase, epoch, batch, running_loss)\n",
    "            \n",
    "            if batch % 20 == 0:\n",
    "                log_name = str(datetime.now().date()) + iteration\n",
    "                batch_log.write(log_dir, log_name)\n",
    "                \n",
    "            if print_loss:\n",
    "                print(\"loss: {}\".format(running_loss), flush=True)\n",
    "                print('---------------', flush=True)\n",
    "            \n",
    "            if save_masks and phase == 'val':\n",
    "                outputs = sigmoid_function(outputs)\n",
    "                # need to fix before running\n",
    "                outputs_dir = \"data/outputs/results/\" + str(datetime.now().date())\n",
    "                os.makedirs(outputs_dir, exist_ok=True)\n",
    "                threshold = 0.05\n",
    "                j = 0\n",
    "                for locations in paths:\n",
    "                    img = Image.open(locations)\n",
    "                    num = locations.replace(\"./data/train/photos/\", \"\").replace(\".png\", \"\")\n",
    "#                     num = locations.replace(\"./data/validation/photos/\", \"\").replace(\".png\", \"\")\n",
    "                    for threshold in [0.05, .25, .5, .75]:\n",
    "                        img = data_factory.showMaskOnImage(img,outputs[j], threshold)\n",
    "                        img.save(outputs_dir  + \"/train-\" + str(num) + \"-\" + str(epoch) + \"-t\" + str(threshold) + \".png\",\"PNG\")\n",
    "                    j += 1\n",
    "                \n",
    "        val_loss /= num_batch\n",
    "        epoch_log.log(phase, 0, epoch, val_loss)\n",
    "        \n",
    "        epoch_log.write(log_dir, \"epoch - \"+ str(datetime.now().date()) + iteration)    \n",
    "\n",
    "#             if show_live_loss and phase == 'train':\n",
    "#                 logs['log loss'] = epoch_loss\n",
    "#                 logs['accuracy'] = 1 - epoch_loss\n",
    "#                 liveloss.update(logs)\n",
    "#                 liveloss.draw()\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "                #input(\"please enter any key to continue\")\n",
    "\n",
    "#             if output_tensors:\n",
    "#                 return inputs, outputs, paths\n",
    "\n",
    "        #save best copy of  model\n",
    "        #if phase == 'val' and epoch_loss < best_loss:\n",
    "#         if epoch_loss < best_loss:\n",
    "#             best_loss = epoch_loss\n",
    "#             torch.save(model, LOAD_LOCATION)\n",
    "#             torch.save(model, SAVE_LOCATION)\n",
    "#             torch.save(model.state_dict(), LOAD_LOCATION + \"-\" + str(datetime.now().date()) + iteration) \n",
    "#             #torch.save(model, SAVE_LOCATION)\n",
    "#             #torch.save(model, SAVE_LOCATION.replace(\"model\", \"model_best\"))\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    \n",
    "    print('Training complete in {:.1f}m {:.1f}s'.format(time_elapsed // 60, time_elapsed % 60), flush=True)\n",
    "    \n",
    "    log_name = str(datetime.now().date()) + iteration\n",
    "    batch_log.write(log_dir, log_name)\n",
    "    \n",
    "    epoch_log.write(log_dir, \"epoch - \"+ str(datetime.now().date()) + iteration)\n",
    "    \n",
    "    #logs_dir = \"data/logs/\" + str(datetime.now().date())\n",
    "    #save_object(log, logs_dir)\n",
    "    \n",
    "    #completed model\n",
    "    #torch.save(model,SAVE_LOCATION)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from ./data/models/model_best\n"
     ]
    }
   ],
   "source": [
    "from unet_models import *\n",
    "\n",
    "#imports related to UNet\n",
    "if newTraining:\n",
    "    model = UNet1(num_classes=1, num_filters=32, pretrained=True, is_deconv=True)\n",
    "#     model = UNet16_5(num_classes=1, num_filters=32, pretrained=True, is_deconv=True)\n",
    "    \n",
    "#     print('initializing model with random weights', flush=True)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.center.children())[1].weight)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.dec5.children())[1].weight)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.dec4.children())[1].weight)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.dec3.children())[1].weight)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.dec2.children())[1].weight)\n",
    "#     torch.nn.init.xavier_uniform_(next(model.dec1.children()).weight)\n",
    "#     torch.nn.init.xavier_uniform_(model.final.weight)\n",
    "                           \n",
    "else:\n",
    "    print(\"loading weights from\", LOAD_LOCATION, flush=True)\n",
    "    #model = torch.load(SAVE_LOCATION)\n",
    "    model = torch.load(LOAD_LOCATION)\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "#criterion = DICELossMultiClass()\n",
    "#criterion = IOU_BCELoss()\n",
    "\n",
    "#Observe adjustments in learning rate\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.05, weight_decay=0, amsgrad=False, eps=0.1)\n",
    "\n",
    "# Osscilate between high and low learning rates over time\n",
    "exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=EPOCHS,eta_min=0.001)  \n",
    "\n",
    "\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Val-Batch 1/1\n",
      "loss: 0.3602752387523651\n",
      "---------------\n",
      "Training complete in 1.0m 42.2s\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=EPOCHS)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    torch.save(model, INTERRUPTED_LOCATION)\n",
    "    print('Saved interrupt', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    inputs, outputs, paths = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=EPOCHS)\n",
    "    #batch = \n",
    "except KeyboardInterrupt:\n",
    "    torch.save(model, INTERRUPTED_LOCATION)\n",
    "    print('Saved interrupt', flush=True)\n",
    "\n",
    "# for tensor in labels:\n",
    "#     #tensor = labels[0]\n",
    "#     tensor_max_value = torch.max(tensor)\n",
    "#     print(tensor_max_value)\n",
    "#     print(type(tensor_max_value.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dataGenerator.dataGenerator(416)\n",
    "j = 0\n",
    "outputs_dir = \"data/outputs/\" + str(datetime.now().date())\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "threshold = 0.05\n",
    "batch = 3\n",
    "\n",
    "for locations in paths:\n",
    "    img = Image.open(locations)\n",
    "    img = dat.showMaskOnImage(img,outputs[j], threshold)\n",
    "    img.save(outputs_dir  + \"/batch_\" + str(batch) + \"-\" + str(j) + \".png\",\"PNG\")\n",
    "    #img.show()\n",
    "    j += 1\n",
    "\n",
    "#Cells\n",
    "outputs[0]\n",
    "    \n",
    "#Cells\n",
    "locations = \"/data/photos/999.png\"\n",
    "loc = locations.replace(\"/data/photos/\", \"\").replace(\".png\", \"\")\n",
    "\n",
    "print(locations)\n",
    "print(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet16_5(num_classes=1, num_filters=32, pretrained=True, is_deconv=True)\n",
    "model.load_state_dict(torch.load(LOAD_LOCATION+'_test-2019-04-23-3'))\n",
    "torch.save(model, LOAD_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    ")\n",
    "input = torch.rand(1, 3, 216, 216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 216, 216])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 108, 108])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.models.vgg16(pretrained=True).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
